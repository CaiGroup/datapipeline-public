import pandas as pd
import numpy as np
from pathlib import Path

"""
Run this directly in your experiment directory.
e.g. snakemake -c1 -j100 --profile /home/lombelet/data-pipeline-lincoln/snakemake/slurm alignment/offsets.json
"""
PIPE_ROOT = config.get('pipeline_root', '/home/lombelet/data-pipeline-lincoln')
EXP_TAB = 'exp_tab.csv'

# This generates EXP_TAB, so really should be in another file because we need to read
# EXP_TAB in for the subsequent rules.
globbed = glob_wildcards('data/HybCycle_{hyb, \d+}/MMStack_Pos{position, \d+}.ome.tif')
filenames = [f'data/HybCycle_{h}/MMStack_Pos{p}.ome.tif' for p, h in zip(globbed.position, globbed.hyb)]

df = pd.DataFrame({'position': globbed.position, 'hyb': globbed.hyb, 'filename': filenames})
df['position'] = df['position'].astype(int)
df['hyb'] = df['hyb'].astype(int)

df = df.set_index(['position', 'hyb']).sort_index()
df.to_csv(EXP_TAB)

def make_align_name(position, hyb):
    return f'alignment/pos_{position}_hyb_{hyb}_offset'

def absolute(path):
    return str(Path(path).absolute().resolve())

def for_each_pos_each_hyb(fmt_string):
    df = pd.read_csv(EXP_TAB)
    pos_hybs = df[['position', 'hyb']].values

    fmt_string = str(fmt_string)

    return [fmt_string.format(position=p, hyb=h) for p, h in pos_hybs]

wildcard_constraints:
    hyb='\d+',
    position='\d+'

rule align_matlab_dapi:
    input:
       'data/HybCycle_0/MMStack_Pos{position}.ome.tif',
       'data/HybCycle_{hyb}/MMStack_Pos{position}.ome.tif' 
    params:
        dest_dir='alignment/pos_{position}_hyb_{hyb}',
        script_loc=str(Path(PIPE_ROOT, 'align_scripts', 'matlab_dapi.py')),
    output:
        temp(Path('alignment', 'pos_{position}_hyb_{hyb}', 'offset.txt')),  
        temp(Path('alignment', 'pos_{position}_hyb_{hyb}', 'dapi_s.mat'))
    threads: 4
    shell:
        "python {params.script_loc} --fixed_src {input[0]} --moving_src {input[1]} --dest_dir {params.dest_dir}"

rule combine_offsets:
    input:
        exp_tab=EXP_TAB,
        offsets=for_each_pos_each_hyb(Path('alignment', 'pos_{position}_hyb_{hyb}', 'offset.txt'))
    output:
        Path('alignment', 'offsets.json')
    run:
        offsets_combined = {}

        for file in input['offsets']:
            try:
                offsets = open(file, 'r').read()
            except:
                continue

            key = Path(file).parts[1]
            offsets = offsets.split(',')[:2]
            offsets = [float(o) for o in offsets]
            offsets_combined[key] = offsets
        import json
        json.dump(offsets_combined, open('alignment/offsets.json', 'w'), indent=2)
